{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import GPy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Load NetCDF data using xarray\n",
    "file_path = 'path'\n",
    "data = xr.open_dataset(file_path)\n",
    "\n",
    "# Extract variables (assuming 'ws' is wind speed and 'tp' is total precipitation)\n",
    "ws10 = data['ws'].values  # Shape: (time, latitude, longitude)\n",
    "tp = data['tp'].values  # Shape: (time, latitude, longitude)\n",
    "\n",
    "# Normalize the data, ignoring NaNs\n",
    "ws10_mean = np.nanmean(ws10)\n",
    "ws10_std = np.nanstd(ws10)\n",
    "tp_mean = np.nanmean(tp)\n",
    "tp_std = np.nanstd(tp)\n",
    "\n",
    "normalized_ws10 = (ws10 - ws10_mean) / ws10_std\n",
    "normalized_tp = (tp - tp_mean) / tp_std\n",
    "\n",
    "# Prepare the input (X) and output (Y) data\n",
    "time_indices, lat_indices, lon_indices = np.meshgrid(\n",
    "    np.arange(normalized_ws10.shape[0]),\n",
    "    np.arange(normalized_ws10.shape[1]),\n",
    "    np.arange(normalized_ws10.shape[2]),\n",
    "    indexing='ij'\n",
    ")\n",
    "\n",
    "X = np.vstack([time_indices.ravel(), lat_indices.ravel(), lon_indices.ravel()]).T\n",
    "Y = np.vstack([normalized_ws10.ravel(), normalized_tp.ravel()]).T\n",
    "\n",
    "# Filter out NaNs\n",
    "valid_mask = ~np.isnan(Y).any(axis=1) & ~np.isnan(X).any(axis=1)\n",
    "X_valid = X[valid_mask]\n",
    "Y_valid = Y[valid_mask]\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_valid, Y_valid, test_size=0.1, random_state=42)\n",
    "\n",
    "### Independent Single-Output GPs ###\n",
    "kernel = RBF()\n",
    "gpr = GaussianProcessRegressor(kernel=kernel)\n",
    "\n",
    "# Using MultiOutputRegressor to handle independent outputs\n",
    "sogp_model = MultiOutputRegressor(gpr)\n",
    "sogp_model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions with SOGP\n",
    "Y_pred_sogp = sogp_model.predict(X_test)\n",
    "\n",
    "# Evaluate SOGP performance\n",
    "mse_sogp = ((Y_test - Y_pred_sogp) ** 2).mean(axis=0)\n",
    "\n",
    "### Correlated Multi-Output GPs ###\n",
    "\n",
    "X_train_ws10 = np.hstack([X_train, np.zeros((X_train.shape[0], 1))])\n",
    "X_train_tp = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "X_train_combined = np.vstack([X_train_ws10, X_train_tp])\n",
    "\n",
    "Y_train_combined = np.hstack([Y_train[:, 0], Y_train[:, 1]])\n",
    "\n",
    "# Train a single GP on the combined data\n",
    "kernel_combined = GPy.util.multioutput.LCM(input_dim=3, num_outputs=2, kernels_list=[GPy.kern.RBF(3), GPy.kern.RBF(3)])\n",
    "gpr_combined = GPy.models.GPCoregionalizedRegression([X_combined], [Y_combined], kernel=kernel)\n",
    "#gpr_combined.fit(X_train_combined, Y_train_combined)\n",
    "gpr_combined.optimize()\n",
    "\n",
    "\n",
    "# Prepare the test data with an extra dimension for output indexing\n",
    "X_test_ws10 = np.hstack([X_test, np.zeros((X_test.shape[0], 1))])\n",
    "X_test_tp = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "X_test_combined = np.vstack([X_test_ws10, X_test_tp])\n",
    "\n",
    "# Make predictions\n",
    "Y_pred_combined = gpr_combined.predict_noiseless(X_test_combined)\n",
    "\n",
    "# Separate the predictions\n",
    "Y_pred_ws10_combined = Y_pred_combined[:X_test.shape[0]]\n",
    "Y_pred_tp_combined = Y_pred_combined[X_test.shape[0]:]\n",
    "\n",
    "# Combine the predictions into the original shape\n",
    "Y_pred_mogp = np.vstack([Y_pred_ws10_combined, Y_pred_tp_combined]).T\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, meansolute_error, meansolute_percentage_error\n",
    "\n",
    "# For Single Output Gaussian Processes (SOGPs)\n",
    "mse_sogp = mean_squared_error(Y_test, Y_pred_sogp, multioutput='raw_values')\n",
    "mae_sogp = meansolute_percentage_error(Y_test, Y_pred_sogp, multioutput='raw_values')\n",
    "print(\"MSE for independent SOGPs:\", mse_sogp)\n",
    "print(\"MAPE for independent SOGPs:\", mae_sogp)\n",
    "\n",
    "# For Multi-Output Gaussian Processes (MOGPs)\n",
    "mse_mogp = mean_squared_error(Y_test, Y_pred_mogp, multioutput='raw_values')\n",
    "mae_mogp = meansolute_percentage_error(Y_test, Y_pred_mogp, multioutput='raw_values')\n",
    "print(\"MSE for correlated MOGP:\", mse_mogp)\n",
    "print(\"MAPE for correlated MOGP:\", mae_mogp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 定义纬度和经度的索引\n",
    "lat_indices = [5, 6]\n",
    "lon_indices = [50, 49]\n",
    "# 提取经纬度数据\n",
    "latitudes = data['latitude'].values  # 你的纬度坐标名可能不同，根据实际情况调整\n",
    "longitudes = data['longitude'].values  # 你的经度坐标名可能不同，根据实际情况调整\n",
    "# 查找对应的经纬度\n",
    "lat_values = [latitudes[idx] for idx in lat_indices]\n",
    "lon_values = [longitudes[idx] for idx in lon_indices]\n",
    "\n",
    "# 创建3x3的图表\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 6))\n",
    "\n",
    "# Extract time series for the chosen point\n",
    "def extract_time_series(data, lat_index, lon_index):\n",
    "    return data[:, lat_index, lon_index]\n",
    "\n",
    "# 遍历所有纬度和经度的组合\n",
    "for i, lat in enumerate(lat_indices):\n",
    "    for j, lon in enumerate(lon_indices):\n",
    "\n",
    "        # 为每个组合提取时间序列\n",
    "        ws10_series = extract_time_series(normalized_ws10, lat, lon)\n",
    "        tp_series = extract_time_series(normalized_tp, lat, lon)\n",
    "\n",
    "        # Predicted values for the chosen point from SOGP\n",
    "        X_test_point = np.array([[i, lat, lon] for i in range(normalized_ws10.shape[0])])\n",
    "        Y_pred_point_sogp = sogp_model.predict(X_test_point)\n",
    "        Y_pred_point_ws10_sogp = Y_pred_point_sogp[:, 0]\n",
    "        Y_pred_point_tp_sogp = Y_pred_point_sogp[:, 1]\n",
    "\n",
    "        # Predicted values for the chosen point from MOGP\n",
    "        X_test_point_ws10 = np.hstack([X_test_point, np.zeros((X_test_point.shape[0], 1))])\n",
    "        X_test_point_tp = np.hstack([X_test_point, np.ones((X_test_point.shape[0], 1))])\n",
    "        X_test_point_combined = np.vstack([X_test_point_ws10, X_test_point_tp])\n",
    "\n",
    "        Y_pred_point_combined = gpr_combined.predict_noiseless(X_test_point_combined)\n",
    "        Y_pred_point_ws10_mogp = Y_pred_point_combined[:X_test_point.shape[0]]\n",
    "        Y_pred_point_tp_mogp = Y_pred_point_combined[X_test_point.shape[0]:]\n",
    "\n",
    "\n",
    "        # 剪裁时间序列\n",
    "        time_range = np.arange(ws10_series.shape[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 绘制 ws10 和 tp\n",
    "        ax = axes[i, j]\n",
    "        # 假设这里是预测值的绘制\n",
    "        ax.plot(time_range, ws10_series, 'b-',label='True ws10')\n",
    "        ax.plot(time_range, Y_pred_point_ws10_sogp,n,'r--', label='Predicted ws10 (SOGP)')\n",
    "        ax.plot(time_range, Y_pred_point_ws10_mogp,'g--', label='Predicted ws10 (MOGP)')\n",
    "\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Normalized ws10')\n",
    "        ax.set_title(f'Wind Speed at ({lat_values[i]}N, {lon_values[j]}W) For Hurricane XXX(Name)')\n",
    "        ax.legend()\n",
    "\n",
    "# 调整布局以避免重叠\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
